# 🎙️ Speaker Recognition using Machine Learning

## 📌 Overview
This project focuses on **Speaker Recognition**, which is the task of identifying or verifying a speaker’s identity based on their voice. Using audio signal processing and machine learning techniques, the system extracts features from voice samples and trains a model to recognize different speakers.

---

## 🚀 Features
- Preprocessing of audio dataset (voice samples).
- Feature extraction (MFCC, Spectrograms, etc.).
- Training of Machine Learning / Deep Learning models.
- Evaluation of speaker recognition accuracy.
- Extendable to real-time speaker verification.

---

## 🛠️ Technologies Used
- Python 3.x
- NumPy
- Pandas
- Librosa (for audio feature extraction)
- Scikit-learn
- Matplotlib / Seaborn
- Jupyter Notebook

---

## 📂 Project Structure
Speaker_recognition_Project_(1).ipynb # Main notebook
README.md # Project documentation


---

## ⚡ Installation
Clone the repository and install the dependencies:

git clone https://github.com/YourUsername/SpeakerRecognition.git
cd SpeakerRecognition
pip install -r requirements.txt


## ▶️ Usage

Open the Jupyter Notebook:

jupyter notebook Speaker_recognition_Project_(1).ipynb


Run the cells step by step to:

Load the dataset (voice samples).

Extract features (MFCCs, etc.).

Train the speaker recognition model.

Evaluate accuracy on test samples.

## 📊 Results
- Training accuracy: ~99.25%
- Validation accuracy: ~95.88%
- Training loss: ~0.025
- Validation loss: ~0.123



## 📌 Future Work

Real-time speaker verification using microphone input.

Deploy as a web app or mobile app.

Improve accuracy with advanced deep learning architectures (CNNs, RNNs, Transformers).

## 👨‍💻 Authors

- **Muhammed Ahmed** – [MoAhmed229](https://github.com/MoAhmed229)

- **Malak Waleed** – [malak-waleed1](https://github.com/malak-waleed1)
